{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mister</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>quilter</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Apostle</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  word_id     word  start_time  end_time  offset  length  \\\n",
       "0            0        0   Mister        0.03      0.08    0.05       6   \n",
       "1            0        1  quilter        0.08      1.02    0.94       7   \n",
       "2            0        2       is        1.02      1.04    0.02       2   \n",
       "3            0        3      the        1.04      1.05    0.01       3   \n",
       "4            0        4  Apostle        1.05      2.01    0.96       7   \n",
       "\n",
       "   syllable_count  \n",
       "0               2  \n",
       "1               2  \n",
       "2               1  \n",
       "3               1  \n",
       "4               2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import syllables\n",
    "\n",
    "data = pd.read_csv(\"Output_New.csv\", header=None)\n",
    "data.columns = ['sentence_id', 'word_id', 'word', 'start_time', 'end_time', 'offset']\n",
    "data['length'] = data.apply (lambda row: len(row[\"word\"]), axis=1)\n",
    "data['syllable_count'] = data.apply (lambda row: syllables.estimate(row[\"word\"]), axis=1)\n",
    "xtrain = np.array(data.length.values.astype(np.float32)).reshape(-1,1)\n",
    "ycorrect = np.array(data.offset.values.astype(np.float32)).reshape(-1,1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>prev_word_1_length</th>\n",
       "      <th>prev_word_2_length</th>\n",
       "      <th>prev_word_3_length</th>\n",
       "      <th>prev_word_4_length</th>\n",
       "      <th>next_word_1_length</th>\n",
       "      <th>next_word_2_length</th>\n",
       "      <th>next_word_3_length</th>\n",
       "      <th>next_word_4_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mister</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>quilter</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>is</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Apostle</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  word_id     word  start_time  end_time  offset  length  \\\n",
       "0            0        0   Mister        0.03      0.08    0.05       6   \n",
       "1            0        1  quilter        0.08      1.02    0.94       7   \n",
       "2            0        2       is        1.02      1.04    0.02       2   \n",
       "3            0        3      the        1.04      1.05    0.01       3   \n",
       "4            0        4  Apostle        1.05      2.01    0.96       7   \n",
       "\n",
       "   syllable_count  prev_word_1_length  prev_word_2_length  prev_word_3_length  \\\n",
       "0               2                 NaN                 NaN                 NaN   \n",
       "1               2                 6.0                 NaN                 NaN   \n",
       "2               1                 7.0                 6.0                 NaN   \n",
       "3               1                 2.0                 7.0                 6.0   \n",
       "4               2                 3.0                 2.0                 7.0   \n",
       "\n",
       "   prev_word_4_length  next_word_1_length  next_word_2_length  \\\n",
       "0                 NaN                 7.0                 2.0   \n",
       "1                 NaN                 2.0                 3.0   \n",
       "2                 NaN                 3.0                 7.0   \n",
       "3                 NaN                 7.0                 2.0   \n",
       "4                 6.0                 2.0                 3.0   \n",
       "\n",
       "   next_word_3_length  next_word_4_length  \n",
       "0                 3.0                 7.0  \n",
       "1                 7.0                 2.0  \n",
       "2                 2.0                 3.0  \n",
       "3                 3.0                 6.0  \n",
       "4                 6.0                 7.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['prev_word_1_length'] = data.length.shift()\n",
    "data['prev_word_2_length'] = data.length.shift(2)\n",
    "data['prev_word_3_length'] = data.length.shift(3)\n",
    "data['prev_word_4_length'] = data.length.shift(4)\n",
    "data['next_word_1_length'] = data.length.shift(-1)\n",
    "data['next_word_2_length'] = data.length.shift(-2)\n",
    "data['next_word_3_length'] = data.length.shift(-3)\n",
    "data['next_word_4_length'] = data.length.shift(-4)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These comments required for new input csv file!\n",
    "# data['tmp_offset'] = -1 * (data.start_time - data.start_time.shift(-1))\n",
    "# data['offset'] = data.apply(lambda row: row['tmp_offset'] if row['tmp_offset'] >= 0 else row['end_time'] - row['start_time'], axis=1)\n",
    "data['sentence_length'] = data.sentence_id.map(data.groupby('sentence_id').count().word_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    for j in range(4):\n",
    "        data.iloc[i, 8+j] = 0 if data.word_id[i] <= j else data.iloc[i, 8+j]\n",
    "#         better version but showing some error! Need to debug it!\n",
    "#         data['prev_word_{k}_length'.format(k=j+1)][i] = 0 if data.word_id[i] <= j else data['prev_word_{k}_length'.format(k=j+1)][i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    for j in range(4):\n",
    "        data.iloc[i, 12+j] = 0 if (data.sentence_length[i] - data.word_id[i] - 1) <= j else data.iloc[i, 12+j]\n",
    "#         better version but showing some error! Need to debug it!\n",
    "#         data['next_word_{k}_length'.format(k=j+1)][i] = 0 if (data.sentence_length[i] - data.word_id[i] -1) <= j else data['next_word_{k}_length'.format(k=j+1)][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['part_of_speech'] = data.apply (lambda row: nltk.pos_tag(row[\"word\"])[0][1] , axis=1)\n",
    "data['is_noun'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] in ['NN','NNS','NNP','NNPS'] else 0, axis=1)\n",
    "data['is_adjective'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] in ['JJ','JJR','JJS'] else 0, axis=1)\n",
    "data['is_pronoun'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] in ['PRP','PRP$','WP','WP$'] else 0, axis=1)\n",
    "data['is_adverb'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] in ['RB','RBR','RBS','WRB'] else 0, axis=1)\n",
    "data['is_verb'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] in ['VB','VBD','VBG','VBN','VBP','VBZ'] else 0, axis=1)\n",
    "data['is_determiner'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] in ['DT','WDT'] else 0, axis=1)\n",
    "data['is_foreign_word'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] == 'FW' else 0, axis=1)\n",
    "data['is_conjunction'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] == 'CC' else 0, axis=1)\n",
    "data['is_preposition'] = data.apply (lambda row: 1 if nltk.pos_tag(row[\"word\"])[0][1] == 'IN' else 0, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence_id', 'word_id', 'word', 'start_time', 'end_time', 'offset',\n",
       "       'length', 'syllable_count', 'prev_word_1_length', 'prev_word_2_length',\n",
       "       'prev_word_3_length', 'prev_word_4_length', 'next_word_1_length',\n",
       "       'next_word_2_length', 'next_word_3_length', 'next_word_4_length',\n",
       "       'sentence_length', 'part_of_speech', 'is_noun', 'is_adjective',\n",
       "       'is_pronoun', 'is_adverb', 'is_verb', 'is_determiner',\n",
       "       'is_foreign_word', 'is_conjunction', 'is_preposition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns = ['length', 'syllable_count',\n",
    "                        'prev_word_1_length','prev_word_2_length','prev_word_3_length','prev_word_4_length',\n",
    "                        'next_word_1_length','next_word_2_length','next_word_3_length','next_word_4_length',\n",
    "                        'sentence_length','is_noun', 'is_adjective','is_pronoun', 'is_adverb', 'is_verb', \n",
    "                        'is_determiner','is_foreign_word', 'is_conjunction', 'is_preposition']\n",
    "train_x = train[training_columns]\n",
    "train_y = train.iloc[:,5]\n",
    "\n",
    "test_x = test[training_columns]\n",
    "test_y = test.iloc[:,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8540603 0.        0.1459397 0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.        0.\n",
      " 0.        0.        0.        0.        0.        0.       ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
    "regr.fit(train_x, train_y)\n",
    "print(regr.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = regr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17652044248922033"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "score_for_test_set = mean_squared_error(hyp, test_y)\n",
    "score_for_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
